---
title: "HPCell"
output: github_document
---

<!-- badges: start -->

[![Lifecycle:maturing](https://img.shields.io/badge/lifecycle-maturing-blue.svg)](https://www.tidyverse.org/lifecycle/#maturing)

<!-- badges: end -->

# HPCell

HPCell is a workflow framework designed for use with single-cell RNA sequencing studies (scRNA-seq), which helps in processing and analyzing the vast amount of data generated by these studies. It is built on the Targets framework within the R programming language, offering an approachable solution for those already proficient in R. The key features of HPCell include:


-   **Native R Pipeline:** HPCell is developed to work natively within the R environment, enhancing usability for R users without requiring them to learn new, workflow-specific languages.

-   **High Performance Computing Support:** HPCell supports scaling for large datasets and enables parallel processing of tasks on High Performance Computing platforms.

-   **Reproducibility and Consistency:** The framework ensures reproducibility and consistent execution environments through automatic dependency generation.

## Install HPCell

```{r, eval=FALSE}

remote::install_github("stemangiola/HPCell")

```


```{r message=FALSE, warning=FALSE}
library(HPCell)
library(tidybulk)
```

## High-performance single-cell, pseudobulk random-effect modelling

The interface is intuitive and consistent with `tidybulk` `test_differential_abundance()`. By default `HPCell` uses `test_differential_abundance(..., method = "glmmSeq_lme4")`

<!-- ```{r} -->

<!-- # Setup your job submission system -->
<!-- slurm = crew.cluster::crew_controller_slurm( -->
<!--   name = "slurm", -->
<!--   slurm_memory_gigabytes_per_cpu = 5, -->
<!--   slurm_cpus_per_task = 1, -->
<!--   workers = 200, -->
<!--   verbose = T -->
<!-- ) -->

<!-- # Perform the analyses.  -->
<!-- tidySummarizedExperiment::se |> -->
<!--   keep_abundant(factor_of_interest = dex) |> -->

<!--   # Spread the workload onto 200 workers and collects the results seamlessly -->
<!--   test_differential_abundance_hpc( -->
<!--     ~ dex + (1 | cell) -->
<!--   ) -->
<!-- ``` -->

## High-performance single-cell preprocessing

Flowchart

<https://app.mural.co/t/covid7029/m/covid7029/1656652076667/c47e104697d76b36b8dee3bd05d8de9d96d99efd?sender=udbe1ea99c9618abb07196978>

### load input data

```{r message=FALSE, warning=FALSE}
# Load input data (can be a list of directories or single directory)
library(Seurat)
library(scRNAseq)
input_data_path =  tempfile(tmpdir = ".") |> paste0(".rds")
HeOrganAtlasData(ensembl=FALSE,location=FALSE)|>
  as.Seurat(data = NULL) |>
  saveRDS(input_data_path)
```

### Execute Targets workflow and load results

```{r}
# Running the pipeline
preprocessed_seurat = run_targets_pipeline(
    input_data = input_data_path,
    tissue = "pbmc",
    filter_empty_droplets = TRUE,
    sample_column = "Tissue"
)

# Load results
preprocessed_seurat

```

### Include reference dataset for azimuth annotation

Details to come.

```{r, eval=FALSE} 

input_reference_path  <- "reference_azimuth.rds" 
reference_url <- "https://atlas.fredhutch.org/data/nygc/multimodal/pbmc_multimodal.h5seurat" 
download.file(reference_url, input_reference_path) 
LoadH5Seurat(input_reference_path) |> saveRDS(input_reference_path)
```


# HPCell Pipeline Documentation

## Overview
The `run_targets_pipeline` function orchestrates a targeted workflow for processing single-cell RNA sequencing data, using the `targets` R package. This documentation explains the pipeline's structure, methods used, and provides code snippets to illustrate its operation. It's designed to help beginners understand both the how and the why of each step.

## Introduction to `targets`
The `targets` package in R automates and streamlines the execution of complex data analysis pipelines. It manages dependencies between steps (targets) and only reruns parts of the workflow that have changed. Users can also map targets dynamically to manage a list of input and/or parameters. 

## Pipeline Steps and Methods

```{r setup, include=FALSE}
run_targets_pipeline <- function(
    input_data, 
    store = "./", 
    input_reference = NULL,
    tissue,
    computing_resources = crew_controller_local(workers = 1), 
    debug_step = NULL,
    filter_empty_droplets = TRUE, 
    RNA_assay_name = "RNA", 
    sample_column = "sample"
) {
  sample_column = enquo(sample_column)
  
  # Saving Input Parameters
  # User-defined parameters and data are saved as .rds files. This step ensures that all 
  # necessary information is available to the targets pipeline as input targets.
  
  input_data |> saveRDS("input_file.rds")
  input_reference |> saveRDS("input_reference.rds")
  tissue |> saveRDS("tissue.rds")
  computing_resources |> saveRDS("temp_computing_resources.rds")
  filter_empty_droplets |> saveRDS("filter_empty_droplets.rds")
  sample_column |> saveRDS("sample_column.rds")
  
  # Configuring'targets' 
  # Using tar_option_set, we configure global settings for the targets pipeline, specifying 
  # required packages, memory options, and computing resources.
  
  tar_script({
    
    library(targets)
    library(tarchetypes)
    library(crew)
    library(crew.cluster)
    
    computing_resources = readRDS("temp_computing_resources.rds")
    #-----------------------#
    # Packages
    #-----------------------#
    tar_option_set(
      packages = c(
        "HPCell",
        "readr",
        "dplyr",
        "tidyr",
        "ggplot2",
        "purrr",
        "Seurat",
        "tidyseurat",
        "glue",
        "scater",
        "DropletUtils",
        "EnsDb.Hsapiens.v86",
        "here",
        "stringr",
        "readr",
        "rlang",
        "scuttle",
        "scDblFinder",
        "ggupset",
        "tidySummarizedExperiment",
        "broom",
        "tarchetypes",
        "SeuratObject",
        "SingleCellExperiment", 
        "SingleR", 
        "celldex", 
        "tidySingleCellExperiment", 
        "tibble", 
        "magrittr",
        "qs", 
        "S4Vectors"
      ),
      memory = "transient",
      garbage_collection = TRUE,
      #trust_object_timestamps = TRUE,
      storage = "worker", 
      retrieval = "worker", 
      #error = "continue",         
      format = "qs", 
      debug = debug_step, # Set the target you want to debug.
      # cue = tar_cue(mode = "never") # Force skip non-debugging outdated targets.
      controller = computing_resources
    )
    
    # Defining targets 
    # Targets represent each step in the data analysis process. 
    # For instance, filtering empty droplets, annotating cell types, and identifying cell cycles 
    # are defined as individual targets within the pipeline.
    
    # Managing dependencies 
    # Each analysis step depends on the output of previous steps. targets tracks these dependencies automatically. 
    
    # Mapping
    # Target are defined that operates over a list of datasets or a range of parameters. 
    # Allows the application the same processing steps to multiple samples or datasets.
    
    target_list = list(
      tar_target(file, "input_file.rds", format = "rds"), 
      tar_target(read_file, readRDS("input_file.rds")),
      #tar_target(reference_file, "input_reference.rds", format = "rds"), 
      tar_target(reference_file, readRDS("input_reference.rds")), 
      tar_target(tissue_file, readRDS("tissue.rds")), 
      tar_target(filtered_file, readRDS("filter_empty_droplets.rds")), 
      tar_target(sample_column_file, readRDS("sample_column.rds")))
    
    #-----------------------#
    # Pipeline
    #-----------------------#
    target_list|> c(list(
      
      # Define input files
      # tarchetypes::tar_files(name= input_track, 
      #                        read_file, 
      #                        deployment = "main"),
      # tarchetypes::tar_files(name= reference_track,
      #                        read_reference_file, 
      #                        deployment = "main"),
      tar_target(filter_empty_droplets, filtered_file, deployment = "main"),
      tar_target(tissue, tissue_file, deployment = "main"),
      tar_target(sample_column, sample_column_file, deployment = "main"),
      tar_target(reference_label_coarse, reference_label_coarse_id(tissue), deployment = "main"), 
      tar_target(reference_label_fine, reference_label_fine_id(tissue), deployment = "main"), 
      # Reading input files
      tar_target(input_read, readRDS(read_file),
                 pattern = map(read_file),
                 iteration = "list", deployment = "main"),

      tar_target(reference_read, reference_file, deployment = "main"),
      
      # Identifying empty droplets
      tar_target(empty_droplets_tbl,
                 empty_droplet_id(input_read, filter_empty_droplets),
                 pattern = map(input_read),
                 iteration = "list"),
      
      # Cell cycle scoring
      tar_target(cell_cycle_score_tbl, cell_cycle_scoring(input_read,
                                                          empty_droplets_tbl),
                 pattern = map(input_read,
                               empty_droplets_tbl),
                 iteration = "list"),
      
      # Annotation label transfer
      tar_target(annotation_label_transfer_tbl,
                 annotation_label_transfer(input_read,
                                           empty_droplets_tbl,
                                           reference_read),
                 pattern = map(input_read,
                               empty_droplets_tbl),
                 iteration = "list"),
      
      # Alive identification
      tar_target(alive_identification_tbl, alive_identification(input_read,
                                                                empty_droplets_tbl,
                                                                annotation_label_transfer_tbl),
                 pattern = map(input_read,
                               empty_droplets_tbl,
                               annotation_label_transfer_tbl),
                 iteration = "list"),
      
      # Doublet identification
      tar_target(doublet_identification_tbl, doublet_identification(input_read,
                                                                    empty_droplets_tbl,
                                                                    alive_identification_tbl,
                                                                    annotation_label_transfer_tbl,
                                                                    reference_label_fine),
                 pattern = map(input_read,
                               empty_droplets_tbl,
                               alive_identification_tbl,
                               annotation_label_transfer_tbl),
                 iteration = "list"),
      
      # Non-batch variation removal
      tar_target(non_batch_variation_removal_S, non_batch_variation_removal(input_read,
                                                                            empty_droplets_tbl,
                                                                            alive_identification_tbl,
                                                                            cell_cycle_score_tbl),
                 pattern = map(input_read,
                               empty_droplets_tbl,
                               alive_identification_tbl,
                               cell_cycle_score_tbl),
                 iteration = "list"),
      
      # Pre-processing output
      tar_target(preprocessing_output_S, preprocessing_output(tissue,
                                                              non_batch_variation_removal_S,
                                                              alive_identification_tbl,
                                                              cell_cycle_score_tbl,
                                                              annotation_label_transfer_tbl,
                                                              doublet_identification_tbl),
                 pattern = map(non_batch_variation_removal_S,
                               alive_identification_tbl,
                               cell_cycle_score_tbl,
                               annotation_label_transfer_tbl,
                               doublet_identification_tbl),
                 iteration = "list"),
      
      # pseudobulk preprocessing for each sample 
      tar_target(create_pseudobulk_sample, create_pseudobulk(preprocessing_output_S, 
                                                                   assays = "RNA", 
                                                                   x = c(Tissue, Cell_type_in_each_tissue)), 
                 pattern = map(preprocessing_output_S), 
                 iteration = "list"),
      
      tar_target(pseudobulk_merge_all_samples, pseudobulk_merge(create_pseudobulk_sample, 
                                                                assays = "RNA", 
                                                                x = c(Tissue)), 
                 pattern = map(create_pseudobulk_sample), 
                 iteration = "list"),
      
      tar_target(calc_UMAP_dbl_report, calc_UMAP(input_read), 
                 pattern = map(input_read), 
                 iteration = "list")
      ))
  }, script = glue("{store}.R"), ask = FALSE)
  
  # Executing the Pipeline
  # The tar_make() function initiates the execution of the pipeline, 
  # processing each target according to the dependencies defined.
  
  tar_make(
    script = glue("{store}.R"),
    store = store, 
    callr_function = NULL
  )
  
  message(glue("HPCell says: you can read your output executing tar_read(preprocessing_output_S, store = \"{store}\")"))
  
  # Accessing Results
  # After the pipeline execution, results can be accessed using tar_read()
  
  tar_read(preprocessing_output_S, store = store)
}
```



