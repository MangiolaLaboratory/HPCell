---
title: "tidybulk - part of tidyTranscriptomics"
output: github_document
---

<!-- badges: start -->

[![Lifecycle:maturing](https://img.shields.io/badge/lifecycle-maturing-blue.svg)](https://www.tidyverse.org/lifecycle/#maturing)

<!-- badges: end -->

# HPCell

HPCell is a workflow framework designed for use with single-cell RNA sequencing studies (scRNA-seq), which helps in processing and analyzing the vast amount of data generated by these studies. It is built on the Targets framework within the R programming language, offering an approachable solution for those already proficient in R. The key features of HPCell include:

-   **Native R Pipeline:** HPCell is developed to work natively within the R environment, enhancing usability for R users without requiring them to learn new, workflow-specific languages.

-   **High Performance Computing Support:** HPCell supports scaling for large datasets and enables parallel processing of tasks on High Performance Computing platforms.

-   **Reproducibility and Consistency:** The framework ensures reproducibility and consistent execution environments through automatic dependency generation.

## Install HPCell

```{r, eval=FALSE}

remote::install_github("stemangiola/HPCell")

```

```{r message=FALSE, warning=FALSE}
library(HPCell)
library(tidybulk)

# # To keep the original non-tidy SummarizedExperiment view
# options("restore_SummarizedExperiment_show" = TRUE)
```

## High-performance single-cell, pseudobulk random-effect modelling

### One datasets/cell-type

The interface is intuitive and consistent with `tidybulk` `test_differential_abundance()`. By default `HPCell` uses `test_differential_abundance(..., method = "glmmSeq_lme4")`

```{r}

# Setup your job submission system
slurm = crew.cluster::crew_controller_slurm(
  name = "slurm",
  slurm_memory_gigabytes_per_cpu = 5,
  slurm_cpus_per_task = 1,
  workers = 200,
  verbose = T
)

# Perform the analyses. 
tidySummarizedExperiment::se |>
  keep_abundant(factor_of_interest = dex) |>
  
  # Spread the workload onto 200 workers and collects the results seamlessly
  test_differential_abundance_hpc(
    ~ dex + (1 | cell), 
    computing_resources = slurm
  )
```

### Many datasets/cell-types

Sometime we do pseudobulk analyses for each cell type. HPCell allows to scale all those, in a coherent paralleisation to the HPC.

This would be the input dataset

```{r, eval=FALSE}

# A tibble: 22 × 3
   cell_type_harmonised data            formula  
   <chr>                <list>          <list>   
 1 b memory             <SmmrzdEx[,35]> <formula>
 2 b naive              <SmmrzdEx[,35]> <formula>
 3 plasma               <SmmrzdEx[,35]> <formula>
 4 ilc                  <SmmrzdEx[,38]> <formula>
 5 cd4 th1              <SmmrzdEx[,37]> <formula>
 6 cd4 th2              <SmmrzdEx[,40]> <formula>
 7 mait                 <SmmrzdEx[,26]> <formula>
 8 cd8 naive            <SmmrzdEx[,28]> <formula>
 9 cd8 tcm              <SmmrzdEx[,36]> <formula>
10 macrophage           <SmmrzdEx[,21]> <formula>
# ℹ 12 more rows
# ℹ Use `print(n = ...)` to see more rows

```

And here the call to the `map` version of `test_differential_abundance_hpc`

```{r, eval=FALSE}
nested_se |>
      mutate(data = map2_test_differential_abundance_hpc(
        data,
        formula ,
        computing_resources = slurm
      ))
```

This is the output 

```{r, eval=FALSE}
# A tibble: 22 × 3
   cell_type_harmonised data            formula  
   <chr>                <list>          <list>   
 1 b memory             <SmmrzdEx[,35]> <formula>
 2 b naive              <SmmrzdEx[,35]> <formula>
 3 plasma               <SmmrzdEx[,35]> <formula>
 4 ilc                  <SmmrzdEx[,38]> <formula>
 5 cd4 th1              <SmmrzdEx[,37]> <formula>
 6 cd4 th2              <SmmrzdEx[,40]> <formula>
 7 mait                 <SmmrzdEx[,26]> <formula>
 8 cd8 naive            <SmmrzdEx[,28]> <formula>
 9 cd8 tcm              <SmmrzdEx[,36]> <formula>
10 macrophage           <SmmrzdEx[,21]> <formula>
# ℹ 12 more rows
# ℹ Use `print(n = ...)` to see more rows
```

## High-performance single-cell preprocessing

Flowchart

<https://app.mural.co/t/covid7029/m/covid7029/1656652076667/c47e104697d76b36b8dee3bd05d8de9d96d99efd?sender=udbe1ea99c9618abb07196978>

### load input data

```{r message=FALSE, warning=FALSE}
# Load input data (can be a list of directories or single directory)
library(Seurat)
library(scRNAseq)
input_data_path =  tempfile(tmpdir = ".") |> paste0(".rds")
HeOrganAtlasData(ensembl=FALSE,location=FALSE)[, 1:400] |>
  as.Seurat(data = NULL) |>
  saveRDS(input_data_path)
```

### Execute Targets workflow and load results

```{r}

# Running the pipeline
preprocessed_seurat = run_targets_pipeline(
    input_data = input_data_path,
    tissue = "pbmc",
    filter_empty_droplets = TRUE,
    sample_column = "Tissue"
)

# Load results
preprocessed_seurat

```

### Include reference dataset for azimuth annotation

Details to come.

```{r, eval=FALSE}

input_reference_path  <- "reference_azimuth.rds" 
reference_url <- "https://atlas.fredhutch.org/data/nygc/multimodal/pbmc_multimodal.h5seurat" 
download.file(reference_url, input_reference_path) 
LoadH5Seurat(input_reference_path) |> saveRDS(input_reference_path)
```
